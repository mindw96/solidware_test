{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('solid': conda)"
  },
  "interpreter": {
   "hash": "afcf0587a0b9d8ad376f2b267ff70998ceccd3030669e3e753cc259109bd3fa3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self, x_train='', y_train=''):\n",
    "    self.x_data = x_train\n",
    "    self.y_data = y_train\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.FloatTensor(self.x_data[idx])\n",
    "    y = torch.FloatTensor(self.y_data[idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=df.quantile(0.10)\n",
    "q2=df.quantile(0.90)\n",
    "qua =q2-q1\n",
    "\n",
    "df=df[~((df<(q1-(1.9*qua)))|(df>(q2+(1.9*qua)))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['quality'].values.tolist())\n",
    "X = np.array(df.drop(labels=['quality'], axis=1).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.33, random_state=96)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, test_size=0.33, random_state=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_scaler = StandardScaler()\n",
    "X_train_SS = ss_scaler.fit_transform(X_train)\n",
    "X_valid_SS = ss_scaler.transform(X_valid)\n",
    "X_test_SS = ss_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(685, 11) (338, 11) (505, 11) (685,) (338,) (505,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_SS.shape, X_valid_SS.shape, X_test_SS.shape, y_train.shape, y_valid.shape ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainval = np.expand_dims(y_trainval, axis=1)\n",
    "y_train = np.expand_dims(y_train, axis=1)\n",
    "y_valid = np.expand_dims(y_valid, axis=1)\n",
    "y_test = np.expand_dims(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X_train_SS, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(torch.nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        print('Regression Model Init')\n",
    "        super(Regression, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(input, 30)\n",
    "        self.layer2 = torch.nn.Linear(30, 50)\n",
    "        self.layer3 = torch.nn.Linear(50, 100)\n",
    "        self.layer4 = torch.nn.Linear(100, 200)\n",
    "        self.layer5 = torch.nn.Linear(200, 100)\n",
    "        self.layer6 = torch.nn.Linear(100, 30)\n",
    "        self.layer7 = torch.nn.Linear(30, output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.relu(self.layer5(x))\n",
    "        x = F.relu(self.layer6(x))\n",
    "        x = self.layer7(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Regression Model Init\n",
      "0 / 10000\n",
      "100 / 10000\n",
      "200 / 10000\n",
      "300 / 10000\n",
      "400 / 10000\n",
      "500 / 10000\n",
      "600 / 10000\n",
      "700 / 10000\n",
      "800 / 10000\n",
      "900 / 10000\n",
      "1000 / 10000\n",
      "1100 / 10000\n",
      "1200 / 10000\n",
      "1300 / 10000\n",
      "1400 / 10000\n",
      "1500 / 10000\n",
      "1600 / 10000\n",
      "1700 / 10000\n",
      "1800 / 10000\n",
      "1900 / 10000\n",
      "2000 / 10000\n",
      "2100 / 10000\n",
      "2200 / 10000\n",
      "2300 / 10000\n",
      "2400 / 10000\n",
      "2500 / 10000\n",
      "2600 / 10000\n",
      "2700 / 10000\n",
      "2800 / 10000\n",
      "2900 / 10000\n",
      "3000 / 10000\n",
      "3100 / 10000\n",
      "3200 / 10000\n",
      "3300 / 10000\n",
      "3400 / 10000\n",
      "3500 / 10000\n",
      "3600 / 10000\n",
      "3700 / 10000\n",
      "3800 / 10000\n",
      "3900 / 10000\n",
      "4000 / 10000\n",
      "4100 / 10000\n",
      "4200 / 10000\n",
      "4300 / 10000\n",
      "4400 / 10000\n",
      "4500 / 10000\n",
      "4600 / 10000\n",
      "4700 / 10000\n",
      "4800 / 10000\n",
      "4900 / 10000\n",
      "5000 / 10000\n",
      "5100 / 10000\n",
      "5200 / 10000\n",
      "5300 / 10000\n",
      "5400 / 10000\n",
      "5500 / 10000\n",
      "5600 / 10000\n",
      "5700 / 10000\n",
      "5800 / 10000\n",
      "5900 / 10000\n",
      "6000 / 10000\n",
      "6100 / 10000\n",
      "6200 / 10000\n",
      "6300 / 10000\n",
      "6400 / 10000\n",
      "6500 / 10000\n",
      "6600 / 10000\n",
      "6700 / 10000\n",
      "6800 / 10000\n",
      "6900 / 10000\n",
      "7000 / 10000\n",
      "7100 / 10000\n",
      "7200 / 10000\n",
      "7300 / 10000\n",
      "7400 / 10000\n",
      "7500 / 10000\n",
      "7600 / 10000\n",
      "7700 / 10000\n",
      "7800 / 10000\n",
      "7900 / 10000\n",
      "8000 / 10000\n",
      "8100 / 10000\n",
      "8200 / 10000\n",
      "8300 / 10000\n",
      "8400 / 10000\n",
      "8500 / 10000\n",
      "8600 / 10000\n",
      "8700 / 10000\n",
      "8800 / 10000\n",
      "8900 / 10000\n",
      "9000 / 10000\n",
      "9100 / 10000\n",
      "9200 / 10000\n",
      "9300 / 10000\n",
      "9400 / 10000\n",
      "9500 / 10000\n",
      "9600 / 10000\n",
      "9700 / 10000\n",
      "9800 / 10000\n",
      "9900 / 10000\n",
      "10000 / 10000\n",
      "best MSE :  0.41724123591161755\n"
     ]
    }
   ],
   "source": [
    "best_mse = 1\n",
    "\n",
    "model = Regression(11, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0005) \n",
    "train_loss = []\n",
    "nb_epochs = 10000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_cnt = 0\n",
    "\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_sample, y_sample = samples\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            output = model(x_sample)\n",
    "            criterion = torch.nn.MSELoss()\n",
    "            loss = criterion(output, y_sample)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x_sample.size(0)\n",
    "        num_cnt += len(y_sample)\n",
    "\n",
    "    epoch_loss = float(running_loss / num_cnt)\n",
    "\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    x_test_tensor = torch.FloatTensor(X_valid_SS)\n",
    "    predictions = model(x_test_tensor).tolist()\n",
    "    mse = np.sum((y_valid - predictions)**2) / len(predictions)\n",
    "\n",
    "    if best_mse > mse:\n",
    "        best_mse = mse\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    if epoch % 100 == 0:\n",
    "        print('{} / {}'.format(epoch, nb_epochs))\n",
    "print('best MSE : ',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4030854037705683 0.6348900721940518 0.08866726801003112 8.866726801003113\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "x_test_tensor = torch.FloatTensor(X_test_SS)\n",
    "predictions = model(x_test_tensor).tolist()\n",
    "mse = np.sum((y_test - predictions)**2) / len(predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.sum(np.abs((y_test - predictions)/y_test))/len(predictions)\n",
    "mape = mae * 100\n",
    "\n",
    "print(mse, rmse, mae, mape)"
   ]
  },
  {
   "source": [
    "Result  \n",
    "\n",
    "Data : Standard Scaling  \n",
    "Best Pytorch Regression MSE : 0.4030\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}